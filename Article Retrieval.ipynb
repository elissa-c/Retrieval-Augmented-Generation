{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7796657,"sourceType":"datasetVersion","datasetId":4564591},{"sourceId":5112,"sourceType":"modelInstanceVersion","modelInstanceId":3900}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Instalations and imports","metadata":{}},{"cell_type":"code","source":"!pip install -q -U langchain\n!pip install -q -U sentence-transformers\n!pip install -q -U chromadb\n!pip install -q -U bitsandbytes\n!pip install -q -U accelerate ","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:07:24.501781Z","iopub.execute_input":"2024-05-06T19:07:24.502626Z","iopub.status.idle":"2024-05-06T19:09:01.493478Z","shell.execute_reply.started":"2024-05-06T19:07:24.502590Z","shell.execute_reply":"2024-05-06T19:09:01.492417Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\n\nfrom langchain.document_loaders import TextLoader, DataFrameLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores import Chroma\n\nimport torch\n\nfrom transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:01.495391Z","iopub.execute_input":"2024-05-06T19:09:01.495718Z","iopub.status.idle":"2024-05-06T19:09:18.649141Z","shell.execute_reply.started":"2024-05-06T19:09:01.495688Z","shell.execute_reply":"2024-05-06T19:09:18.648261Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-06 19:09:08.505030: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-06 19:09:08.505159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-06 19:09:08.640403: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading and preprocessing the dataset","metadata":{}},{"cell_type":"code","source":"# Load the data from a local cvs file or from a kaggle dataset\n\n#df = load_dataset(\"csv\", data_files='medium.csv') \ndf = pd.read_csv('/kaggle/input/1300-towards-datascience-medium-articles-dataset/medium.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:18.650249Z","iopub.execute_input":"2024-05-06T19:09:18.650830Z","iopub.status.idle":"2024-05-06T19:09:18.881829Z","shell.execute_reply.started":"2024-05-06T19:09:18.650803Z","shell.execute_reply":"2024-05-06T19:09:18.880759Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data = []\nfor index in range(len(df)):\n    topic = df['Title'][index]\n    text = df['Text'][index]\n    for i in range(0, len(text), 400):\n        if i + 400 < len(text):\n            data.append([topic, text[i:i+400]])\n        else:\n            data.append([topic, text[i:]])\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:18.885124Z","iopub.execute_input":"2024-05-06T19:09:18.885515Z","iopub.status.idle":"2024-05-06T19:09:20.073033Z","shell.execute_reply.started":"2024-05-06T19:09:18.885481Z","shell.execute_reply":"2024-05-06T19:09:20.072242Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"articles = DataFrameLoader(df, page_content_column = \"Title\") #saving the articles as documents\ndocument = articles.load()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:20.074083Z","iopub.execute_input":"2024-05-06T19:09:20.074367Z","iopub.status.idle":"2024-05-06T19:09:20.207271Z","shell.execute_reply.started":"2024-05-06T19:09:20.074342Z","shell.execute_reply":"2024-05-06T19:09:20.206484Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"splitter = RecursiveCharacterTextSplitter(chunk_size = 300, chunk_overlap = 10) # splitting the documents to fit the \ndocOutput = splitter.split_documents(document)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:20.208406Z","iopub.execute_input":"2024-05-06T19:09:20.208704Z","iopub.status.idle":"2024-05-06T19:09:20.282748Z","shell.execute_reply.started":"2024-05-06T19:09:20.208678Z","shell.execute_reply":"2024-05-06T19:09:20.281918Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Creating the database for similarity search\nCreating a Chroma database to use for similarity search with the prompts given. Retrieving relevant articles to the topic for further processes. ","metadata":{}},{"cell_type":"code","source":"model = HuggingFaceEmbeddings(model_name=\"avsolatorio/GIST-small-Embedding-v0\")","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:20.283942Z","iopub.execute_input":"2024-05-06T19:09:20.284382Z","iopub.status.idle":"2024-05-06T19:09:37.216560Z","shell.execute_reply.started":"2024-05-06T19:09:20.284348Z","shell.execute_reply":"2024-05-06T19:09:37.215676Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcaa2238ad8245bbb126d09fc1c8cd93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04e373e40ca2453793229809aeaf5ed9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/68.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e71c1fc68e6241be8aa004be03dfb448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4158b99e2740426094ab0a2e6f6cfabf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/719 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95c8c6cc949944eeb1754aaae1c951ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c391757f4ecc44d99a1ed51797061b89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dcb776060c54e0a84740361b10ee6c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac17b64b43274c60bc92a3c2a89815ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"197a9dec08704137859edf7e58d46b1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1f15b1ebe74cd8a51f2fc1ed244393"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c9a2cccd99e4ddfbec049c249b99cb3"}},"metadata":{}}]},{"cell_type":"code","source":"chroma_db = Chroma.from_documents(documents=docOutput, embedding=model, persist_directory=\"chroma_db\")\nretriever = chroma_db.as_retriever()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:37.218006Z","iopub.execute_input":"2024-05-06T19:09:37.218309Z","iopub.status.idle":"2024-05-06T19:09:41.615892Z","shell.execute_reply.started":"2024-05-06T19:09:37.218282Z","shell.execute_reply":"2024-05-06T19:09:41.614892Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def retrieve_articles(query,k=3, raw = False):\n    result = \"\"\n    docs = chroma_db.similarity_search(query, k = k)\n    print(f\"Query: {query}\")\n    print(f\"Retrieved documents: {len(docs)}\")\n    for doc in docs:\n        doc_details = doc.to_json()['kwargs']\n        result += f\"Source: {doc_details['page_content']} \\n\"\n        result += f\"Text: {doc_details['metadata']['Text'][:100]} \\n\\n\"\n    if raw==False :\n        return result\n    else: \n        return docs","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:13:27.962672Z","iopub.execute_input":"2024-05-06T19:13:27.963538Z","iopub.status.idle":"2024-05-06T19:13:27.969379Z","shell.execute_reply.started":"2024-05-06T19:13:27.963507Z","shell.execute_reply":"2024-05-06T19:13:27.968476Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Generating the answer based on the articles found\nSetting up the Mistral 7B model, creating a prompt of the query and the context found in the articles and feeding it into  the model. ","metadata":{}},{"cell_type":"code","source":"def convert_text(query):\n    docs = retrieve_articles(query, raw = True)\n    text_found = \"\"  # Relevant text in the similar articles\n    for doc in docs:\n        doc_details = doc.to_json()['kwargs']\n        text_found += f\"\\n{doc_details['metadata']['Text']}\"\n    return text_found, docs","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:13:54.811383Z","iopub.execute_input":"2024-05-06T19:13:54.812188Z","iopub.status.idle":"2024-05-06T19:13:54.817306Z","shell.execute_reply.started":"2024-05-06T19:13:54.812155Z","shell.execute_reply":"2024-05-06T19:13:54.816081Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:41.641598Z","iopub.execute_input":"2024-05-06T19:09:41.641942Z","iopub.status.idle":"2024-05-06T19:09:41.650615Z","shell.execute_reply.started":"2024-05-06T19:09:41.641910Z","shell.execute_reply":"2024-05-06T19:09:41.649954Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model_name='/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1'","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:41.651806Z","iopub.execute_input":"2024-05-06T19:09:41.652390Z","iopub.status.idle":"2024-05-06T19:09:41.659212Z","shell.execute_reply.started":"2024-05-06T19:09:41.652358Z","shell.execute_reply":"2024-05-06T19:09:41.658441Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:41.660383Z","iopub.execute_input":"2024-05-06T19:09:41.660661Z","iopub.status.idle":"2024-05-06T19:09:41.785942Z","shell.execute_reply.started":"2024-05-06T19:09:41.660638Z","shell.execute_reply":"2024-05-06T19:09:41.785170Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"textmodel = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        quantization_config=bnb_config,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:09:41.786911Z","iopub.execute_input":"2024-05-06T19:09:41.787164Z","iopub.status.idle":"2024-05-06T19:11:31.051423Z","shell.execute_reply.started":"2024-05-06T19:09:41.787142Z","shell.execute_reply":"2024-05-06T19:11:31.050378Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40b847ee202740689d837acaab20fae5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"text_generation_pipeline = pipeline(  #creating the pipeline\n    \"text-generation\",\n    model=textmodel,\n    tokenizer = tokenizer,\n    torch_dtype =  torch.float16,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:11:31.052613Z","iopub.execute_input":"2024-05-06T19:11:31.052902Z","iopub.status.idle":"2024-05-06T19:11:31.057501Z","shell.execute_reply.started":"2024-05-06T19:11:31.052877Z","shell.execute_reply":"2024-05-06T19:11:31.056645Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def print_answer(query, prompt, result, docs):    \n    answer = f\"\"\"Answer to the query: {query} \\n\n    {result[0][\"generated_text\"][len(prompt):]}... \\n\n    This answer was created based on articles: \\n\n    \"\"\" + \"\\n \".join([f\"{doc.to_json()['kwargs']['page_content']}\" for doc in docs])\n\n    print(answer)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:11:40.354787Z","iopub.execute_input":"2024-05-06T19:11:40.355159Z","iopub.status.idle":"2024-05-06T19:11:40.362753Z","shell.execute_reply.started":"2024-05-06T19:11:40.355130Z","shell.execute_reply":"2024-05-06T19:11:40.361775Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def answer_query(query):\n    text_found, docs = convert_text(query)\n    \n    prompt = f\"Answer the question in under 150 words based on the context given: {text_found}. The question: {query}\"\n    \n    result = text_generation_pipeline(  # answer generation from the pipeline\n        prompt,\n        do_sample=True,\n        max_new_tokens=150, \n        temperature=0.7, \n        top_k=50, \n        top_p=0.95,\n        num_return_sequences=1,\n    )\n    \n    print_answer(query, prompt, result, docs)\n    return\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:11:47.302691Z","iopub.execute_input":"2024-05-06T19:11:47.303652Z","iopub.status.idle":"2024-05-06T19:11:47.309690Z","shell.execute_reply.started":"2024-05-06T19:11:47.303620Z","shell.execute_reply":"2024-05-06T19:11:47.308673Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"question = 'What is ggplot?'","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:11:51.010622Z","iopub.execute_input":"2024-05-06T19:11:51.011259Z","iopub.status.idle":"2024-05-06T19:11:51.015025Z","shell.execute_reply.started":"2024-05-06T19:11:51.011226Z","shell.execute_reply":"2024-05-06T19:11:51.014124Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(retrieve_articles(question, 2))","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:13:30.945075Z","iopub.execute_input":"2024-05-06T19:13:30.945413Z","iopub.status.idle":"2024-05-06T19:13:30.972666Z","shell.execute_reply.started":"2024-05-06T19:13:30.945388Z","shell.execute_reply":"2024-05-06T19:13:30.971795Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Query: What is ggplot?\nRetrieved documents: 2\nSource: How to Use ggplot2 in Python \nText: Introduction\n\nThanks to its strict implementation of the grammar of graphics, ggplot2 provides an ex \n\nSource: Data visualization with Python Using Seaborn and Plotly_ GDP per Capita & Life Expectency Dataset \nText: Data visualization with Python Using Seaborn and Plotly_ GDP per Capita & Life Expectency Dataset\n\nP \n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"answer_query(question)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:14:53.220663Z","iopub.execute_input":"2024-05-06T19:14:53.221169Z","iopub.status.idle":"2024-05-06T19:15:11.602174Z","shell.execute_reply.started":"2024-05-06T19:14:53.221140Z","shell.execute_reply":"2024-05-06T19:15:11.601209Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Query: What is ggplot?\nRetrieved documents: 3\nAnswer to the query: What is ggplot? \n\n    \n\nGgplot is a powerful data visualization tool. It was created by Hadley Wickham for R and is now also available in Python.\n\nGgplot is based on the concept of the Grammar of Graphics, which provides a way to create any type of graph by combining a set of basic visual elements.\n\nGgplot is very popular among data scientists, as it is easy to use and has a wide range of functions.\n\nOne of the advantages of ggplot is that it is highly customizable. You can change the colors, shapes, and sizes of elements in your graph with ease.\n\nGgplot also allows you to create interactive graphs that you can save as HTML files... \n\n    This answer was created based on articles: \n\n    How to Use ggplot2 in Python\n Data visualization with Python Using Seaborn and Plotly_ GDP per Capita & Life Expectency Dataset\n Quick Code to Spruce Up Your Histograms & Scatterplots\n","output_type":"stream"}]}]}