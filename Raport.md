# Introduction

The Article Retrieval program was made with the goal of implementing RAG (Retrieval Augmented Generation) technique in order to enchance the performance of an generative AI model for query answering. 

# About the project

The program is using a Kaggle 1300+ Towards DataScience Medium Articles Dataset. Using a Chroma database with the articles from the dataset, the program is able to retrieve the most relevant articles for a given query. It is done by similatity search. The retrieved articles are then used to generate an answer to the query. The pompt is generated by combining the question and the articles as context. This prompt is ten fed into teh Mistral 7B model for answer generation.

# Models used

- **Chroma** - I chose the Chroma database because of its simplicity. It is an easy to grasp embedding database with lots of features. The most useful one for this project was the similarity search of variable size. What was also important was the ability to use a custiom embedding model as I could adjust it the the size of model I wanted.

- **Mistral 7B** - It is a large language model with 7.3 bilion parameters. It has geat performance compared to other models and is able to generate high quality answers while maintaining a good speed. In the project I used the Instruct version of the model to directly imput the prompt and get the answer.

- **Langchain** - I used the Langchain library for almost everything else in the project. It is a great tool for working with language models and embedding databases. It has a lot of features that make the work easier and faster. It is also very well documented. I used it for loading the dataframe, creating the Chroma database, spiting the data as well as embedding.


# Challenges
The main problem I encountered was adjusting the models and techniques used to my computational power. The models I started using at first were too big for my GPU and I had to switch to smaller ones. Even my first choice of embedding model tuned out to be too large. At the same time I wanted to achieve the best results with the resources I had. I had to find a balance between the model size and the quality of the results. 

I also encountered problems with the text generation models. I was struugling with different was of inputing the prompt into different models. I was working with a bit of trial and error. After some time I realized I need to do more research on the different types of models I could use and that is when I found the Mistral 7B instruct model. It worked great as it did not require any additional input changes, worked faster then other models and gave great results.

# Further developement

What I see could be done to improve the project is to adjust it for different input data instead of one set dataset to pull from. I could then be expanded into larger project with more data and could be used for various queries. 

I would also want to create a simple UI for the program. Giving it even a simple interface to input the query and get the answer would really elevate it. This could then be used as a type of data mining tool for text data. With the custom dataset input te questions asked could be more specific to the data and the answers could be more detailed. This could have practical applications in various fields.